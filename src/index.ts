import OpenAI from 'openai';
import { Hono } from 'hono';
import {cors} from 'hono/cors';

type Bindings={
	OPEN_AI_KEY:string;
	AI:Ai;
}

const app = new Hono <{Bindings:Bindings}>();


app.use(
	'/*',
	cors({
	  origin: '*',
	  allowHeaders: ['X-Custom-Header', 'Upgrade-Insecure-Requests',"Content-Type"],
	  allowMethods: ['POST', 'GET', 'OPTIONS','PUT'],
	  exposeHeaders: ['Content-Length', 'X-Kuma-Revision'],
	  maxAge: 600,
	  credentials: true,
	})
  )


  app.post('/summarygenerator', async (c) => {
	try {
	  const { transcript } = await c.req.json();

	  if (!transcript) {
		return c.json({ error: 'Transcript is required' }, 400);
	  }

	  const trimmedTranscript = transcript.length > 2000 ? transcript.slice(0, 2000) + "..." : transcript;

	  const messages = [
		{
		  role: "system",
		  content: "You are a friendly assistant. Summarize the YouTube transcript in structured JSON format: {title:'',sections:[{subheading:'',points:['point 1', 'point 2']}]}. Use headings and bullet points.",
		},
		{
		  role: "user",
		  content: trimmedTranscript,
		},
	  ];

	  const response = await c.env.AI.run("@cf/meta/llama-2-7b-chat-fp16", { messages });

	  if (!response) {
		return c.json({ error: 'Failed to generate summary' }, 500);
	  }

	  return c.json(response);
	} catch (error) {
	  console.error("Summary generation error:", error);
	  return c.json({ error: 'Internal Server Error' }, 500);
	}
  });

app.post('/chattoai',async(c)=>{
	const body=await c.req.json();
	const {documentdata,question}=body;
	const messages = [
		{ role: "system", content: "You are a friendly assistant,who contains knowledge in this document "+documentdata+" and removes all the extra components generated by Yjs.Doc and generate remaining meaning full sentences." },
		{
		  role: "user",
		  content: question,
		},
	  ];
	  const response = await c.env.AI.run("@cf/meta/llama-2-7b-chat-fp16", { messages });

	  return  Response.json(response);
})

app.post('/translateDocument',async(c)=>{
	const body=await c.req.json();
	const {documentdata,targetlang}=body;
	//summaries document

	const summaryresponse=await c.env.AI.run("@cf/facebook/bart-large-cnn",{
		input_text:documentdata,
		max_length:1000,
	});
	//translate
	const response= await c.env.AI.run("@cf/meta/m2m100-1.2b",{
		text:summaryresponse.summary,
		source_lang:"english",
		target_lang:targetlang,
	});
	console.log("response",response);
	return new Response(JSON.stringify(response));
})

// app.post('/transcribe', async (c) => {
// 	try {
// 	  const body = await c.req.json<{ youtubeUrl: string }>();

// 	  if (!body.youtubeUrl) {
// 		return c.json({ error: 'Missing YouTube URL' }, 400);
// 	  }

// 	  // Extract YouTube video ID
// 	  const videoId = extractYouTubeId(body.youtubeUrl);
// 	  if (!videoId) {
// 		return c.json({ error: 'Invalid YouTube URL' }, 400);
// 	  }

// 	  // Fetch YouTube audio URL using yt-dlp API
// 	  const audioUrl = await fetchAudioUrl(videoId);
// 	  if (!audioUrl) {
// 		return c.json({ error: 'Failed to fetch audio' }, 500);
// 	  }

// 	  // Send audio to Whisper API for transcription
// 	  const transcript = await transcribeAudio(c.env.OPEN_AI_KEY, audioUrl);
// 	  if (!transcript) {
// 		return c.json({ error: 'Transcription failed' }, 500);
// 	  }

// 	  return c.json({ transcript });
// 	} catch (error) {
// 	  console.error('Error:', error);
// 	  return c.json({ error: 'Internal Server Error' }, 500);
// 	}
//   });

//   // Extract YouTube Video ID
//   function extractYouTubeId(url: string): string | null {
// 	const match = url.match(/(?:youtube\.com\/.*v=|youtu\.be\/)([\w-]+)/);
// 	return match ? match[1] : null;
//   }

//   // Fetch YouTube Audio using yt-dlp API
//   async function fetchAudioUrl(videoId: string): Promise<string | null> {
// 	const response = await fetch(`https://your-yt-dlp-api.com/audio?videoId=${videoId}`);
// 	const data = await response.json();
// 	return data?.audioUrl || null;
//   }

//   // Transcribe YouTube Audio with Whisper API
//   async function transcribeAudio(apiKey: string, audioUrl: string): Promise<string | null> {
// 	const openai = new OpenAI({ apiKey });

// 	const response = await openai.audio.transcriptions.create({
// 	  file: audioUrl,
// 	  model: 'whisper-1',
// 	  language: 'en',
// 	});

// 	return response.text || null;
//   }


export default app;
